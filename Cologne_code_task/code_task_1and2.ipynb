{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Coding question\n### Write in python a function connected_components.\n\nGiven an input binary array A of size \nh´w it finds all connected areas of 1s in the array. For a position A(x,y)=1 in the array any position A(x±1,y±1)=1 is considered as connected.The function should return an array of size h´w where background is assigned 0 and each connected component is assigned a different integer number.\n\n### Solution\n\nIterate through each element of the input 2d array:\n\nFor each iteration, if the element and one of its neighbors are not zero, assign a value to all of the elements in this connected area. Do dfs to mark all connected elements inside the current area, then increase the assigned value by 1. Then go to the next iteration of the element.\n\nTime complexity: O (h * w). It is related to the number of ones in the input array. If the element value equals zero, no need to do DFS. If the element value equals one, dfs will be started to iterate its all connected elements which are equal to one. Then the DFS will change the value into a different integer number other than 1. In one word: DFS will iterate all the elements which equal to one. In the worst scenario, all the elements are equal to one in the input array, then it takes 2 * h * w iteration times.  \n\nSpace complexity: O (h * w). A new 2d array is created; All of the elements of the 2d array are iterated.","metadata":{}},{"cell_type":"code","source":"def assign_cc(input_array): # assign different integer numbers to different connected region for the input array.\n    \n    # x, y: element cooradinates in this particular connected region\n    # assign_value: the value to be assigned in this particular connected region. \n    # connected_area： the area (sum of number of connected components) in this particular connected region\n    def dfs(x, y, assign_value, connected_area):    \n        if connected_area > 0:\n            grid[x][y] = assign_value    \n        for c in [[0, 1], [0, -1], [1, 0], [-1, 0]]: # if there is a connected component in the neighbour, do dfs for it.\n            nx, ny = x + c[0], y + c[1]\n            if 0 <= nx < row and 0 <= ny < col and grid[nx][ny] == 1:\n                connected_area += 1\n                dfs(nx, ny, assign_value, connected_area)         \n        return connected_area\n    \n    grid = np.copy(input_array) # create a new copy for the input array: grid.\n    [row, col] = grid.shape\n    assign_value = 2\n    for i in range(row):\n        for j in range(col):\n            if grid[i][j] == 1:                \n                connected_area = dfs(i, j, assign_value, 0)     \n                if connected_area > 0:\n                    assign_value += 1   \n                    \n    ## if the input array consist of a single connected region only and no other isloated elements\n    ## assign the value 1 the single connected region.    \n    if len(set(grid.flatten())) == 2:\n        grid[grid == 2] = 1\n        \n    return grid","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:03:31.515524Z","iopub.execute_input":"2022-02-13T09:03:31.516241Z","iopub.status.idle":"2022-02-13T09:03:31.527784Z","shell.execute_reply.started":"2022-02-13T09:03:31.516194Z","shell.execute_reply":"2022-02-13T09:03:31.527035Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Test the function\nimport numpy as np\nprint('processing as below:') \nh, w = 4, 3\nnp.random.seed(6)\ninput_array = np.random.randint(0, 2, (h, w) )\nprint(input_array, '\\n\\n')\noutput = assign_cc(input_array)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:06:22.285417Z","iopub.execute_input":"2022-02-13T09:06:22.286156Z","iopub.status.idle":"2022-02-13T09:06:22.294596Z","shell.execute_reply.started":"2022-02-13T09:06:22.286108Z","shell.execute_reply":"2022-02-13T09:06:22.293460Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Data analysis question**\n\nYou have a network for segmenting out cells from a microscopy image that performs good in \nsome types of tissue images and worse in other types, e.g. on the tissue boundary where \nmorphology looks somehow different. To improve the accuracy, it would be beneficial to include \nthe low-performing images in your training set. Labeling of images for segmentation is however \nlaborious.\nWhat would you do speed up or facilitate the image labeling process?* ","metadata":{}},{"cell_type":"markdown","source":"*Say the model is working well on type A cells but not type B cells* \n\n1. Goole if there is any type of open-source model or public annotated dataset similar to type B cells.\n\n2. Label a few type B images, say 10 or 10% of type B images, then use the transfer-learning method to train a model based on B images and labels. See if the model could manage to segment the remaining type B images. \n\n3. Try more data augmentation techniques on type A images and labels, especially the non-rigid transformation: like GridDistortion and ElasticTransform (see the attached pictures and the references). I assume that these non-rigid transformations are not used in the current network. We can re-train the current model with the non-rigid augmented date and then check its performance on the type B images. \n\n4. I assume the cells in type B segmentations are mostly empty inside, the problem is the edge detection. Then we can try some traditional image processing techniques to generate the image edge annotations, such as thresholding, seed filling, and random walk. \n\n5. Try the image registration techniques, rigid or non-rigid, to see if type A images could be registered to type B images in a specific function. If so, we can then fine-tune the current model to infer the type B images based on the registered images via transfer learning.","metadata":{}},{"cell_type":"markdown","source":"Medical image augmentation ref： https://camo.githubusercontent.com/37427c37dbc48402071f0b8fbc62bda0b4724969b29dc30212dfe8af512c1f2b/68747470733a2f2f686162726173746f726167652e6f72672f776562742f31692f66692f777a2f31696669777a79306c78657463346e776a7673732d37316e6b77302e6a706567\n\nhttps://github.com/albumentations-team/albumentations#list-of-augmentations\n\nBioimage augmentatio ref: https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/showcase.ipynb\n\n","metadata":{}}]}